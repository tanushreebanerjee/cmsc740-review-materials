Learning to Importance Sample in
Primary Sample Space
Quan Zheng1, Matthias Zwicker 1
1 University

of Maryland, College Park, USA

Slides adapted from conference presentation:

The 40Â° Annual Conference of the European Association for Computer Graphics

Motivation: Monte Carlo Rendering

Emitter
Camera

Path x
Pixel j

2

Motivation: Monte Carlo Rendering
Rendering equation:
ğ¼ğ¼ğ‘—ğ‘— = ï¿½ ğ‘“ğ‘“ğ‘—ğ‘— ğ‘¥ğ‘¥ ğ‘‘ğ‘‘ğ‘‘ğ‘‘ ğ‘¥ğ‘¥
Î©
integral over all light paths
through pixel j
ğ‘ğ‘

ğ‘“ğ‘“ğ‘—ğ‘— ğ‘¥ğ‘¥ğ‘–ğ‘–
where ğ‘¥ğ‘¥ğ‘–ğ‘– is a random sampled path
Monte Carlo integration: ğ¼ğ¼ğ‘—ğ‘— â‰ˆ ï¿½
ğ‘ğ‘(ğ‘¥ğ‘¥ğ‘–ğ‘– )
ğ‘–ğ‘–=1

Camera

Emitter

Path x
Pixel j

3

Motivation: Importance Sampling
ï‚§ Reduce variance by designing sampling density p proportional to
integrand f, as much as possible

Variance

Design density p so
this is constant, as
much as possible
4

Standard Importance Sampling
ï‚§ Construct paths step by step
ï‚§ In each step, choose new direction using either BSDF sampling, or
light sampling
Emitter
Camera

Ï‰

Pixel j

probability(Ï‰)
âˆ ğµğµğµğµğµğµğµğµ

BSDF importance
sampling

5

Standard Importance Sampling
ï‚§ Construct paths step by step
ï‚§ In each step, choose new direction using either BSDF sampling, or
light sampling
probability(Ï‰) âˆ
emission

Camera
Pixel j

Ï‰

Emitter

Light
sampling

6

Standard Importance Sampling
Disadvantages
ï‚§ Does not consider full complexity of integrand (importance samples at each bounce
separately, instead of importance sampling entire paths)
ï‚§ Approximate models of BSDFs and emitters for importance sampling
ï‚§ Ignores occlusions (visibility function)
ï‚§ Does not include non-local effects such as chains of near specular reflections
ï‚§ Requires separate techniques for effects such as motion blur or depth of field

7

Standard Importance Sampling
Disadvantages
ï‚§ Does not consider full complexity of integrand (importance samples at each bounce
separately, instead of importance sampling entire paths)
ï‚§ Approximate models of BSDFs and emitters for importance sampling
ï‚§ Ignores occlusions (visibility function)
ï‚§ Does not include non-local effects such as chains of near specular reflections
ï‚§ Requires separate techniques for effects such as motion blur or depth of field
Our goals
ï‚§ Use higher dimensional target sampling density that more accurately represents
integrand
ï‚§ Learn how to sample from target density by leveraging neural network
ï‚§ Unified approach that treats renderer as black box, is applicable to any light transport
effect

8

Related Work: Importance Sampling
ï‚§ A priori

ï‚§ Use analytical representations of the integrand [Clarberg05]

9

Related Work: Importance Sampling
ï‚§ A priori

ï‚§ Use analytical representations of the integrand [Clarberg05]

ï‚§ A posteriori

ï‚§ Acquire small set of â€œtrainingâ€ samples of integrand, then fit target density to
acquired training samples
ï‚§
ï‚§
ï‚§
ï‚§

Path guiding by caching [Jesen95, Hey02]
Online learning path guiding [Vorba14, MÃ¼ller17]
Path guiding with reinforced method [Dahm17]
Kd-tree based path guiding [Guo2018]

ï‚§ A combination

ï‚§ Bayesian approach to sample direct illumination [Vevoda18]

10

Related Work: Markov Chain Monte Carlo
ï‚§ Metropolis light transport (MLT) [VG97]
ï‚§ Various mutation techniques and path parameterisations
[JM12, KHD14, LLR15]
ï‚§ Primary sample space MLT (PSSMLT) [KSKAC02]
ï‚§ Multiplexed MLT (MMLT) and combine different space
parameterizations [HKD14, OKH17, BJNJ7]

11

Related Work: Deep Learning for Rendering
ï‚§ Denoise Monte Carlo rendering [BVM*17, CKS*17, VRM*18]
ï‚§ Indirect lighting approximation [RWG*13]
ï‚§ Cloud radiance prediction [KMM*17]
ï‚§ A concurrent work for importance sampling [MMR*18]
https://arxiv.org/abs/1808.03856

12

Preliminaries: Primary Sample Space Integral
Construct path via ray tracing
x=Î¦(ğ‘¦ğ‘¦)

ğ‘¥ğ‘¥2
ğ‘¥ğ‘¥0

ğ²ğ² = ğ‘¦ğ‘¦0 , ğ‘¦ğ‘¦1 , â‹¯ , ğ‘¦ğ‘¦7

Primary sample space (PSS)
(unit hypercube; samples of
random number generator)

Pixel j

Path x

ğ‘¥ğ‘¥1

ğ‘¥ğ‘¥3

Path space â„¦, path x given by
vertex locations xi (surface
form of rendering equation)

13

Preliminaries: Primary Sample Space Integral
Construct path via ray tracing
x=Î¦(ğ‘¦ğ‘¦)

ğ‘¥ğ‘¥2
ğ‘¥ğ‘¥0

Pixel j

Path x

ğ‘¥ğ‘¥1

ğ²ğ² = ğ‘¦ğ‘¦0 , ğ‘¦ğ‘¦1 , â‹¯ , ğ‘¦ğ‘¦7

Primary sample space (PSS)

Path space â„¦

(unit hypercube; samples of
random number generator)

ğœ•ğœ•Î¦(ğ²ğ²)
ğ‘‘ğ‘‘ğ²ğ²
ğ¼ğ¼ğ‘—ğ‘— = ï¿½ ğ‘“ğ‘“ğ‘—ğ‘— ğ‘¥ğ‘¥ ğ‘‘ğ‘‘ğ‘‘ğ‘‘ ğ‘¥ğ‘¥ = ï¿½ ğ‘“ğ‘“ğ‘—ğ‘— Î¦(ğ²ğ²)
ğœ•ğœ•ğ²ğ²
Î©
ğ‘ƒğ‘ƒğ‘†ğ‘†ğ‘†ğ‘†
ğ‘ğ‘

ğ‘“ğ‘“ğ‘—ğ‘— Î¦(ğ²ğ²)
1
ğ¼ğ¼ğ‘—ğ‘— â‰ˆ ï¿½
âˆ’1
ğ‘ğ‘
ğœ•ğœ•Î¦(ğ²ğ²)
ğ‘–ğ‘–=1
ğœ•ğœ•ğ²ğ²

ğ‘¥ğ‘¥3

Path construction from primary
samples corresponds to change
of integration variables x=Î¦(y)

Importance sampling expressed as
change of integration variables
14

Our core idea
ï‚§ Improve importance sampling using primary sample space warping Î¨
ï‚§ Non-linear warp Î¨ leads to warped PSS with non-uniform density
z

Uniform PSS

Î¨

y

Î¨ âˆ’1

Warped PSS,
non-uniform density

15

Our core idea
ï‚§ Improve importance sampling using primary sample space warping Î¨
ï‚§ Non-linear warp Î¨ leads to warped PSS with non-uniform density
z

Uniform PSS

Î¨

y

Î¨ âˆ’1

Warped PSS,
non-uniform density

Î¦

ğ‘¥ğ‘¥0

ğ‘¥ğ‘¥2

ğ‘¥ğ‘¥1

ğ‘¥ğ‘¥3

Existing renderer,
without modifications

16

Non-linear PSS warp and importance sampling
z

Uniform PSS
ğ¼ğ¼ğ‘—ğ‘— = ï¿½ ğ‘“ğ‘“ğ‘—ğ‘— ğ‘¥ğ‘¥ ğ‘‘ğ‘‘ğ‘‘ğ‘‘ ğ‘¥ğ‘¥
Î©

=ï¿½

ğ‘ƒğ‘ƒğ‘†ğ‘†ğ‘†ğ‘†

ğ‘“ğ‘“ğ‘—ğ‘— Î¦ Î¨ ğ³ğ³

Warp
Î¨

Warped PSS,
non-uniform density

ğœ•ğœ•Î¨(ğ³ğ³) ğœ•ğœ•Î¦ Î¨(ğ³ğ³)
ğ‘‘ğ‘‘ğ³ğ³
ğœ•ğœ•ğ³ğ³
ğœ•ğœ•Î¨(ğ³ğ³)

Chain rule
including warp

y

ğ‘ğ‘

Existing renderer
as black box

ğ‘“ğ‘“ğ‘—ğ‘— Î¦ Î¨ ğ³ğ³ğ‘–ğ‘–
1
ğ¼ğ¼ğ‘—ğ‘— â‰ˆ ï¿½
âˆ’1
ğ‘ğ‘
ğœ•ğœ•Î¨(ğ³ğ³
)
ğœ•ğœ•Î¦ Î¨(ğ³ğ³ğ‘–ğ‘– )
ğ‘–ğ‘–
ğ‘–ğ‘–=1
ğœ•ğœ•ğ³ğ³ğ‘–ğ‘–
ğœ•ğœ•Î¨(ğ³ğ³ğ‘–ğ‘– )

Design Î¨ to improve
importance sampling

âˆ’1

17

PSS target density
ï‚§ PSS target density denoted as p(y)=p(Î¨(z))

Ideal goal:
warp Î¨ so that density proportional
to each pixel integrand j in existing renderer

ï‚§ Goal: make it proportional to integrand in PSS
ï‚§ Challenge: each pixel has its own integrand

ï‚§ Simplification: one global target density, instead of per pixel
ï‚§ Using path throughput g, instead of image contribution function fj
Throughput Pixel filter

ï‚§ Global target density

ğ‘“ğ‘“ğ‘—ğ‘— Î¦(ğ‘¦ğ‘¦) = ğ‘”ğ‘” Î¦(ğ‘¦ğ‘¦) â‹… ğ‘Šğ‘Šğ‘—ğ‘— Î¦(ğ‘¦ğ‘¦)
Desired warp

Practical goal:
warp Î¨ so density proportional
to path throughput g in existing renderer
18

Challenges
ï‚§ Target density and its representation
ï‚§ Representation of the warp
ï‚§ Learning the warp

19

Overview
1

3

2

Scenes

Warp
Renderer

Acquire PSS target
density as small set
of samples

Represent warp as neural
network, train to match
target density

Arbitrary
number of
warped PSS
samples

Rendering

20

Represent target density using set of samples
ï‚§ Build a candidate set T, uniformly sampled in PSS
ï‚§ Each sample stores value of target density

ï‚§ Resample a subset S from T that follows target density [TCE05
https://dl.acm.org/doi/10.5555/2383654.2383674], sample-importance resampling
Candidate set, uniformly distributed in PSS,
each sample stores value of target density

Resampled set, distributed
according to target density

Resample

(discard samples with
probability inversely
proportional to target
density)

ğ‘‡ğ‘‡ =Î± â‹… ğ‘†ğ‘† , Î±>1

ğ‘†ğ‘†

21

Target density as invertible warp
ï‚§ Find inverse warp ğ‘§ğ‘§ = Î¨âˆ’1 (ğ‘¦ğ‘¦), such that samples ğ‘¦ğ‘¦ = Î¨ ğ‘§ğ‘§ follow
distribution of target density
Inverse warp
z

ğ‘§ğ‘§ = Î¨ âˆ’1 (ğ‘¦ğ‘¦)
ğ‘¦ğ‘¦ = Î¨(ğ‘§ğ‘§)

y

Forward warp

Uniform density

Target density

22

Maximum likelihood estimation
ï‚§ Inverse warp parametrized by Î¸
ï‚§ Consider density as function of warp parameters Î¸
ğœ•ğœ•Î¨ âˆ’1 ğ‘¦ğ‘¦; ğœƒğœƒ
ğ‘ğ‘ ğœƒğœƒ; ğ‘¦ğ‘¦ =
ğœ•ğœ•ğœ•ğœ•

Density corresponds to determinant of
Jacobian of mapping
https://en.wikipedia.org/wiki/Random_variable#Functions
_of_random_variables

ï‚§ Objective: find the optimal Î¸ to maximize likelihood of samples yi of
target density
ï‚§ â€œFind warp that is most likely to produce target samplesâ€
ğœƒğœƒ âˆ—

1
= ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ max ï¿½ log ğ‘ğ‘ ğœƒğœƒ; ğ‘¦ğ‘¦ğ‘–ğ‘–
ğœƒğœƒ ğ‘ğ‘
ğ‘–ğ‘–

23

Warp representation
ï‚§ Requirements of warp Î¨

ï‚§ Express complex, non-linear mappings
ï‚§ One-to-one mapping
ï‚§ Easy to invert
ï‚§ Evaluate Jacobian determinant efficiently

Key idea: normalizing flows (overview see https://arxiv.org/pdf/1908.09257.pdf)
ï‚§ Represent warp as deep neural network
ï‚§ Leverage normalizing flow architecture, here â€˜real NVPâ€™, Dinh et al.,
ICLR 2017
ï‚§ Satisfies all requirements

24

Real NVP

Element-wise
multiplication

Input z

1 0 1 0
0 1 0 1

Mask b

ğ‘§ğ‘§0 , ğ‘§ğ‘§2
ğ‘§ğ‘§1 , ğ‘§ğ‘§3

ğ‘§ğ‘§ğ‘§0 , ğ‘§ğ‘§ğ‘§2

Coupling layer

ğ‘§ğ‘§ğ‘§0 , ğ‘§ğ‘§1â€² , ğ‘§ğ‘§ğ‘§2 , ğ‘§ğ‘§3â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§1 , ğ‘§ğ‘§2 , ğ‘§ğ‘§3

ï‚§ Affine coupling layer (forward mapping)

Output zâ€™

Real NVP

Element-wise
multiplication

Input z

1 0 1 0
0 1 0 1

Mask b

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

ğ‘§ğ‘§1 , ğ‘§ğ‘§3

ğ‘§ğ‘§1â€² , ğ‘§ğ‘§3â€²

Coupling layer

ğ‘§ğ‘§0 , ğ‘§ğ‘§1â€² , ğ‘§ğ‘§2 , ğ‘§ğ‘§3â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§1 , ğ‘§ğ‘§2 , ğ‘§ğ‘§3

ï‚§ Affine coupling layer (forward mapping)

Output zâ€™

Real NVP

Element-wise
multiplication

Input z

1 0 1 0
0 1 0 1

Mask b

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

ğ‘§ğ‘§1 , ğ‘§ğ‘§3

ğ‘§ğ‘§1â€² , ğ‘§ğ‘§3â€²

Coupling layer

ğ‘§ğ‘§0 , ğ‘§ğ‘§1â€² , ğ‘§ğ‘§2 , ğ‘§ğ‘§3â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§1 , ğ‘§ğ‘§2 , ğ‘§ğ‘§3

ï‚§ Affine coupling layer (forward mapping)

Output zâ€™

ğ‰ğ‰ = exp ï¿½ ğ‘ ğ‘ (ğ‘§ğ‘§ ğ‘ğ‘=1 )ğ‘˜ğ‘˜
ğ‘˜ğ‘˜

27

Real NVP
ï‚§ Inverse of coupling layer

ï‚§ Trivial to compute due to structure of coupling layer
ï‚§ Does not require inverting functions s and t

ï‚§ Implementing functions s and t

ï‚§ Subject to few constraints
ï‚§ Neural networks
ï‚§ Warp parameters Î¸ are trainable network weights

28

Achieving complicated warps
ï‚§ Multiple coupling layers
Stack multiple affine coupling layers
with different masks

Target
samples y

Latent
samples z
Scale

Logit

Coupling
layer

Logit-1

Scale-1

ï‚§ Training under maximum likelihood objective
29

Generating samples for rendering
ï‚§ Use forward mapping Î¨
ï‚§ Input: uniform random PSS vectors
ï‚§ Output: target PSS vectors for rendering
Forward mapping Î¨

Scale
Input

Logit

affine coupling layers

Logit-1

Scale-1
Output

30

Training details
ï‚§ Network initialization

ï‚§ Pretrain the neural network to achieve an identity warp
ï‚§ Reuse the trained weights as initialization

ï‚§ Optimization method

ï‚§ End-to-end scene-dependent training
ï‚§ Adam optimizer with learning rate 10âˆ’4
ï‚§ Batch size 2000

31

Results

32

Results
ï‚§ Practical simplification

ï‚§ Warp at most the first 3 bounces (8D warp, 6D + 2D image plane)
ï‚§ Continue to trace further bounces using uniform PSS parameters

ï‚§ Training dataset sizes

ï‚§ Epp-k (k x 200 x 160 training samples)

ï‚§ Training time

ï‚§ Ranges from 9 to 20 minutes on Nvidia GTX 1070 GPU
ï‚§ We show equal-time comparison. To see timing results, please refer to the
paper.

33

Equal sample count comparison (128spp)
ï‚§ Country Kitchen scene
Reference

MSE

[GBBE18]

PT no warp

Kdtree warp

Our 4D

Our 6D

Our 8D

0.0401

0.0220

0.0170

0.0172

0.0205

Training with epp-16
34

Equal sample count comparison (128spp)
ï‚§ White Room scene
Reference

MSE

[GBBE18]

PT no warp

Kdtree warp

Our 4D

Our 6D

Our 8D

0.2155

0.1235

0.0820

0.0677

0.0832

Training with epp-16
35

Small illumination features
ï‚§ Increasing training data size improves our results, captures small
illumination features
Reference

MSE

PT no warp

0.09275

Training data size = epp x 1002

Ours with training
data size epp=1

Ours with training
data size epp=4

Ours with training
data size epp=64

0.06863

0.05701

0.05038

(Equal sample count 128 spp comparisons)

36

Distribution ray tracing
ï‚§ Pool ball with motion blur
PT no warp

Error plot
Our 4D

MSE errors

Reference

[GBBE18]
Kdtree warp

Training with
epp-16

Sample count

37

Light cluster sampling
ï‚§ Sampling light cluster for direct lighting

ï‚§ Natural History Museum scene with 93 emitters
Unif. sample
emitters

Unif. sample
clusters

Ours

Ours

MSE errors

Reference

Error plot

Rendering sample count
38

Rendering animation sequences
ï‚§ Network reusing to render new camera views
ï‚§ Amortize training costs over several views

View 2
10 degrees

Test loss

View 1
Original

Training time
39

Rendering animation sequences
ï‚§ Network reusing to render new camera views
ï‚§ Amortize training costs over several views

View 3
45 degrees

Test loss

View 1
Original

Training time
40

Rendering animation sequences
ï‚§ Network reusing to render new camera views
ï‚§ Amortize training costs over several views

View 4
90 degrees

Test loss

View 1
Original

Training time
41

Limitations
ï‚§ Computation cost

ï‚§ Acquiring data, and training requires orders of minutes per image
ï‚§ Related to the size of training data, and the scale of neural network

ï‚§ Higher dimensional warps

ï‚§ Experiments up to 12 dimensions
ï‚§ Require large amounts of training data, time
ï‚§ Improvements under equal sample count rendering, but prohibitive training
cost

42

Conclusions
ï‚§ We proposed a novel approach to learn importance sampling
ï‚§ Leverage neural network to perform non-linear warp
ï‚§ Generalize to different tasks
ï‚§ Treat existing renderer as a black box
ï‚§ Effective to reduce variance

ï‚§ Why not represent radiance function directly as neural network,
instead of probability density used for sampling?

ï‚§ Advantage of using probability density: can do unbiased Monte Carlo
sampling
ï‚§ Advantage of using radiance function: may be possible to come up with
different type of algorithm to solve the rendering equation (different from
series expansion and Monte Carlo integration)
43

Quan Zheng, qzhengcs@cs.umd.edu
Matthias Zwicker, zwicker@cs.umd.edu
More information:
https://tinyurl.com/LIS-PSS

Thank you for your attention!
44

45

Real NVP

Output z

ğ‘§ğ‘§0â€² , ğ‘§ğ‘§2â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

Coupling layer

1 0 1 0 Element-wise
multiplication

Mask b

ğ‘§ğ‘§0â€² , ğ‘§ğ‘§1â€² , ğ‘§ğ‘§2â€² , ğ‘§ğ‘§3â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§1 , ğ‘§ğ‘§2 , ğ‘§ğ‘§3

ï‚§ Affine coupling layer (inverse mapping)

Input zâ€™

46

Real NVP

Output z

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

ğ‘§ğ‘§0â€² , ğ‘§ğ‘§2â€²

ğ‘§ğ‘§1 , ğ‘§ğ‘§3

ğ‘§ğ‘§1â€² , ğ‘§ğ‘§3â€²

Coupling layer

1 0 1 0 Element-wise
0 1 0 1 multiplication

Mask b

ğ‘§ğ‘§0â€² , ğ‘§ğ‘§1â€² , ğ‘§ğ‘§2â€² , ğ‘§ğ‘§3â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§1 , ğ‘§ğ‘§2 , ğ‘§ğ‘§3

ï‚§ Affine coupling layer (inverse mapping)

Input zâ€™

47

Real NVP

Output z

ğ‘§ğ‘§0 , ğ‘§ğ‘§2

ğ‘§ğ‘§0â€² , ğ‘§ğ‘§2â€²

ğ‘§ğ‘§1 , ğ‘§ğ‘§3

ğ‘§ğ‘§1â€² , ğ‘§ğ‘§3â€²

Coupling layer

1 0 1 0 Element-wise
0 1 0 1 multiplication

ğ‘§ğ‘§0â€² , ğ‘§ğ‘§1â€² , ğ‘§ğ‘§2â€² , ğ‘§ğ‘§3â€²

ğ‘§ğ‘§0 , ğ‘§ğ‘§1 , ğ‘§ğ‘§2 , ğ‘§ğ‘§3

ï‚§ Affine coupling layer (inverse mapping)

Input zâ€™

Mask b

ğ‰ğ‰ = exp âˆ’ ï¿½ ğ‘ ğ‘ (ğ‘§ğ‘§ ğ‘ğ‘=1 )ğ‘˜ğ‘˜
ğ‘˜ğ‘˜

Note: Do not require inverse of s and t

48

Implementation of Functions s and t
ï‚§ Subject to few constraints
ï‚§ We design them as neural networks
ï‚§ Warp parameters Î¸ are trainable network weights

FC:
BN:
RBi:
RELU:

Fully-connected layer
Batch normalization
i-th residual block
Rectified linear unit

49

Visualization of sample warping
ï‚§ Sample distribution comparison

Uniform input

Kd-tree warp

Ours

ï‚§ Pool Ball scene with motion blur
ï‚§ 3D warping (image plane, time)

ï‚§ Comparison

ï‚§ Ours achieves desired density
ï‚§ Sample distribution of kd-tree
warping is blocky

50

Limitations
ï‚§ Higher dimensional warp

ï‚§ Country Kitchen scene, 12D learning
ï‚§ Require much more training data
ï‚§ Epp 4096 dataset took 26h to train

(Equal sample count 128 spp comparisons)

51

Rendering animation sequences
ï‚§ Network reusing to render new camera views
ï‚§ Amortize training costs over several views

View 1
Original

View 2
10 degrees

View 3
45 degrees

View 4
90 degrees
52

Rendering animation sequences
ï‚§ Network reusing

ï‚§ Generalize to multiple new camera views
ï‚§ Amortize spent training costs over new views
View 3

View 4

Training time

Training time

Training time

Test loss

View 2

53

